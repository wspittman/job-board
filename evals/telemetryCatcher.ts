import { createHash } from "crypto";
import { setAILogging } from "dry-utils-openai";
import type { Context, Log, Scenario } from "./types";

/**
 * Catches and stores AI telemetry logs.
 * It uses a hash of scenario details to mark and later find logs for specific AI calls.
 */
class TelemetryCatcher {
  private logs: Record<string, Log> = {};

  constructor() {}

  /**
   * Creates a modified input context for a scenario.
   * It adds a unique hash to the input item, which is used to identify the corresponding log later.
   * This hash is embedded in the data sent to the LLM.
   */
  createMarkedInput<T>({ action, model, source }: Scenario<T>): Context<T> {
    const { name, input } = source;

    return {
      ...input,
      item: {
        // Add a simple hash to differentiate parallel requests.
        // This DOES affect what is sent to the LLM, but should be opaque to it.
        v: this.hash(action, model.name, name),
        ...input.item,
      },
    };
  }

  /**
   * Stores a log entry.
   * The key for storing the log is extracted from the input string of the log.
   * This assumes the hash generated by `createMarkedInput` is present at a specific position in the input log.
   * @param log The log object to store.
   */
  catch(log: Log): void {
    // The key is the hash embedded in the input string (e.g., "item: { v: 'hash_value', ... }").
    // This extracts the 32-character hash.
    const key = log.in.slice(6, 38);
    this.logs[key] = log;
  }

  /**
   * Finds a log associated with a given context.
   * It uses the hash stored in the context's item to look up the log.
   * @param context The context containing the hash in its item.
   * @returns The found log, or undefined if no log matches.
   */
  find<T>(context: Context<T>): Log | undefined {
    return this.logs[context.item["v"]];
  }

  /**
   * Generates a SHA256 hash from the given arguments and truncates it.
   * @param args Strings to include in the hash.
   * @returns A 32-character hexadecimal hash string.
   */
  private hash(...args: string[]): string {
    return createHash("sha256")
      .update(args.join(""))
      .digest("hex")
      .slice(0, 32);
  }
}

export const catcher = new TelemetryCatcher();

// Configure AI logging to use the TelemetryCatcher instance.
// This intercepts logs from AI calls made via dry-utils-openai.
setAILogging({
  errorFn: (msg, val) => console.error(new Error(msg, { cause: val })),
  aggregatorFn: () => ({ count: 0, counts: {} }),
  logCallFn: (_, log) => catcher.catch(log as Log),
});
